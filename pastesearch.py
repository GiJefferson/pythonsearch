#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                     PYTHON CTRL+C SEARCH & PASTE TOOL                       ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  Vers√£o: 2.1.6 - CORRE√á√ÉO COMPLETA QUEBRAS DE LINHA                        ‚ïë
‚ïë  Data: 2025-06-11                                                           ‚ïë
‚ïë  Autor: Sistema de Busca Inteligente                                        ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  üéØ BUSCA INTELIGENTE DE C√ìDIGO COM 6 ALGORITMOS DIFERENTES                 ‚ïë
‚ïë  üìã SISTEMA PASTE AUTOM√ÅTICO COM COORDENADAS SALVAS                         ‚ïë
‚ïë  üîÑ BACKUP AUTOM√ÅTICO ANTES DE MODIFICA√á√ïES                                 ‚ïë
‚ïë  üÜï CORRE√á√ÉO: C√°lculo preciso com quebras de linha diferentes               ‚ïë
‚ïë  üîß CORRE√á√ÉO: Ajuste autom√°tico de coordenadas no PASTE                     ‚ïë
‚ïë  üö® CORRE√á√ÉO: Mapeamento exato normaliza√ß√£o ‚Üí coordenadas originais         ‚ïë
‚ïë                                                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

import os
import pyperclip
import sys
from datetime import datetime
import xml.etree.ElementTree as ET
from dataclasses import dataclass
from typing import List, Optional, Dict, Any, Tuple
import shutil
import re
import codecs

# üîß Configura√ß√£o de encoding para evitar problemas com caracteres especiais
try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass  # Fallback para sistemas que n√£o suportam reconfigure

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß CONFIGURA√á√ïES GLOBAIS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

PASTA_BASE = r"C:\Users"
EXTENSOES_NEGADAS = {".bak", ".bat"}

# üÜï PADR√ïES DE ARQUIVOS DE BACKUP PARA FILTRAR (v2.1.4)
PADROES_BACKUP = [
    r"\.backup_\d{8}_\d{6}$",  # arquivo.ext.backup_20250610_235341
    r"\.temp\.bak$",           # arquivo.ext.temp.bak
    r"~$",                     # arquivo.ext~
    r"\.orig$",                # arquivo.ext.orig
    r"\.old$",                 # arquivo.ext.old
]

LIMITE_SIMILARIDADE_TIPO5 = 10.0  # üéØ AJUSTE AQUI: Similaridade m√≠nima para TIPO 5 (0.0 a 100.0)

# üÜï CONTROLE DE QUALIDADE DE RESULTADOS (v2.1.1)
LIMITE_PROBABILIDADE_MELHOR_RESULTADO = 80.0  # üéØ AJUSTE AQUI: S√≥ mostra como "melhor resultado" se >= 80% de probabilidade

# üÜï SISTEMA DE SCORES POR TIPO DE BUSCA (v2.1.0)
SCORES_TIPOS = {
    1: 500,  # TIPO 1: 100% literal - m√°xima confiabilidade
    2: 400,  # TIPO 2: arquivo completo igual
    3: 300,  # TIPO 3: normaliza√ß√£o de quebras (mais usado)
    4: 200,  # TIPO 4: com strip nas pontas
    5: 100,  # TIPO 5: base para probabilidade (+ similaridade%)
    6: 350   # üÜï TIPO 6: ignorando U+000D completamente
}

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üÜï ESTRUTURAS DE DADOS (v2.1.0)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class ResultadoBusca:
    """üÜï Estrutura padronizada para resultados de busca (v2.1.0)"""
    tipo: int
    nome_arquivo: str
    caminho_completo: str
    posicao_inicio: int
    posicao_fim: int
    tamanho_texto: int
    texto_original: str
    contexto_inicio: int
    contexto_fim: int
    contexto_texto: str
    similaridade: Optional[float] = None
    texto_encontrado: Optional[str] = None
    
    @property
    def score_confiabilidade(self) -> float:
        """üÜï Calcula score de confiabilidade baseado no tipo e similaridade"""
        score_base = SCORES_TIPOS.get(self.tipo, 0)
        if self.similaridade is not None:
            return score_base + self.similaridade
        return score_base

# üÜï COLETOR GLOBAL DE RESULTADOS (v2.1.0)
resultados_globais: List[ResultadoBusca] = []

def limpar_resultados_globais():
    """üÜï Limpa a lista de resultados globais para nova busca"""
    global resultados_globais
    resultados_globais.clear()
    print("üßπ Resultados globais limpos para nova busca")

def adicionar_resultado_global(tipo: int, arquivo_info: Dict[str, Any]):
    """üÜï Adiciona resultado ao coletor global (v2.1.0)"""
    global resultados_globais
    
    resultado = ResultadoBusca(
        tipo=tipo,
        nome_arquivo=arquivo_info['nome'],
        caminho_completo=arquivo_info['caminho'],
        posicao_inicio=arquivo_info['inicio'],
        posicao_fim=arquivo_info['fim'],
        tamanho_texto=arquivo_info['tamanho'],
        texto_original=arquivo_info['texto_original'],
        contexto_inicio=arquivo_info['contexto_inicio'],
        contexto_fim=arquivo_info['contexto_fim'],
        contexto_texto=arquivo_info['contexto_texto'],
        similaridade=arquivo_info.get('similaridade'),
        texto_encontrado=arquivo_info.get('texto_encontrado')
    )
    
    resultados_globais.append(resultado)
    print(f"‚ûï Resultado TIPO{tipo} adicionado: {arquivo_info['nome']} (score: {resultado.score_confiabilidade:.1f})")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üÜï FUN√á√ïES PARA TRATAMENTO DE U+000D (v2.1.2)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def detectar_problemas_carriage_return(texto):
    """üÜï Detecta e reporta problemas com U+000D no texto (v2.1.2)"""
    count_cr = texto.count('\r')
    count_crlf = texto.count('\r\n')
    count_cr_isolado = count_cr - count_crlf
    
    problemas = []
    if count_cr_isolado > 0:
        problemas.append(f"‚ö†Ô∏è {count_cr_isolado} carriage returns isolados (\\r sem \\n)")
    if count_crlf > 0:
        problemas.append(f"üìù {count_crlf} sequ√™ncias CRLF (\\r\\n)")
    
    if problemas:
        print(f"üîç AN√ÅLISE DE QUEBRAS DE LINHA:")
        for problema in problemas:
            print(f"   {problema}")
    
    return count_cr_isolado > 0

def limpar_carriage_returns(texto):
    """üÜï Remove todos os \\r do texto de forma inteligente (v2.1.2)"""
    # Primeiro converte \r\n para \n
    texto_limpo = texto.replace('\r\n', '\n')
    # Depois remove qualquer \r restante (isolado)
    texto_limpo = texto_limpo.replace('\r', '')
    return texto_limpo

def normalizar_quebras_avancado(texto):
    """üÜï Normaliza√ß√£o avan√ßada que trata todos os tipos de quebras (v2.1.2)"""
    # Remove todos os \r (tanto isolados quanto em \r\n)
    texto_sem_cr = limpar_carriage_returns(texto)
    return texto_sem_cr

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß FUN√á√ïES AUXILIARES ATUALIZADAS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def eh_arquivo_backup(nome_arquivo):
    """üÜï Verifica se o arquivo √© um backup usando padr√µes regex (v2.1.4)"""
    for padrao in PADROES_BACKUP:
        if re.search(padrao, nome_arquivo):
            return True
    return False

def detectar_bom_e_encoding(caminho_arquivo: str) -> Dict[str, Any]:
    """üÜï Detecta BOM e encoding automaticamente"""
    try:
        with open(caminho_arquivo, 'rb') as f:
            raw_bytes = f.read(4)
        
        if raw_bytes.startswith(codecs.BOM_UTF8):
            return {
                'encoding': 'utf-8-sig',
                'bom_size': len(codecs.BOM_UTF8),
                'has_bom': True,
                'detected': 'UTF-8 with BOM'
            }
        elif raw_bytes.startswith(codecs.BOM_UTF16_LE):
            return {
                'encoding': 'utf-16-le',
                'bom_size': len(codecs.BOM_UTF16_LE),
                'has_bom': True,
                'detected': 'UTF-16 LE with BOM'
            }
        else:
            try:
                with open(caminho_arquivo, 'r', encoding='utf-8') as f:
                    f.read(100)
                return {
                    'encoding': 'utf-8',
                    'bom_size': 0,
                    'has_bom': False,
                    'detected': 'UTF-8 without BOM'
                }
            except UnicodeDecodeError:
                return {
                    'encoding': 'latin-1',
                    'bom_size': 0,
                    'has_bom': False,
                    'detected': 'Latin-1 (fallback)'
                }
    except Exception as e:
        return {
            'encoding': 'utf-8',
            'bom_size': 0,
            'has_bom': False,
            'detected': 'UTF-8 (error fallback)'
        }

def ler_arquivo_corrigido_bom(caminho):
    """üîß Vers√£o corrigida que remove BOM corretamente"""
    info_encoding = detectar_bom_e_encoding(caminho)
    
    try:
        # Se tem BOM, usa utf-8-sig que remove automaticamente
        if info_encoding['has_bom'] and 'utf-8' in info_encoding['detected'].lower():
            with open(caminho, 'r', encoding='utf-8-sig', errors='replace') as f:
                conteudo = f.read()
            print(f"   üîß BOM UTF-8 removido automaticamente ({info_encoding['bom_size']} bytes)")
        else:
            # Sem BOM ou outro encoding
            with open(caminho, 'r', encoding=info_encoding['encoding'], errors='replace') as f:
                conteudo = f.read()
            if info_encoding['has_bom']:
                print(f"   üîñ BOM detectado: {info_encoding['bom_size']} bytes")
        
        return conteudo
        
    except Exception as e:
        print(f"‚ùå Erro ao ler {caminho}: {e}")
        # Fallback
        try:
            with open(caminho, 'r', encoding='utf-8', errors='replace') as f:
                return f.read()
        except:
            return ""

def ler_arquivo_com_bom_detection(caminho: str) -> Tuple[str, Dict[str, Any]]:
    """üÜï L√™ arquivo com detec√ß√£o autom√°tica de BOM"""
    info_encoding = detectar_bom_e_encoding(caminho)
    
    try:
        # üö® CORRE√á√ÉO CR√çTICA: Usa utf-8-sig para remover BOM automaticamente
        if info_encoding['has_bom'] and 'utf-8' in info_encoding['detected'].lower():
            with open(caminho, 'r', encoding='utf-8-sig', errors='replace') as f:
                conteudo = f.read()
            print(f"   üîß BOM UTF-8 removido automaticamente ({info_encoding['bom_size']} bytes)")
        else:
            with open(caminho, 'r', encoding=info_encoding['encoding'], errors='replace') as f:
                conteudo = f.read()
            if info_encoding['has_bom']:
                print(f"   üîñ BOM detectado: {info_encoding['bom_size']} bytes")
        
        return conteudo, info_encoding
        
    except Exception as e:
        print(f"‚ùå Erro ao ler {caminho}: {e}")
        try:
            with open(caminho, 'r', encoding='utf-8', errors='replace') as f:
                return f.read(), info_encoding
        except:
            return "", info_encoding

def mapear_posicao_normalizada_para_original_melhorado(
    conteudo_original: str, 
    conteudo_normalizado: str, 
    posicao_normalizada: int
) -> Optional[int]:
    """üÜï Mapeamento preciso que conta diferen√ßas de quebras"""
    if posicao_normalizada >= len(conteudo_normalizado):
        return None
    
    chars_contados = 0
    pos_original = 0
    
    while chars_contados < posicao_normalizada and pos_original < len(conteudo_original):
        char_original = conteudo_original[pos_original]
        
        if char_original == '\r':
            if pos_original + 1 < len(conteudo_original) and conteudo_original[pos_original + 1] == '\n':
                # CRLF: pula 2 chars no original, conta 1 no normalizado
                pos_original += 2
                chars_contados += 1
            else:
                # CR isolado: pula 1 char no original, conta 1 no normalizado
                pos_original += 1
                chars_contados += 1
        else:
            # Char normal: avan√ßa ambos
            pos_original += 1
            chars_contados += 1
    
    return pos_original

def obter_texto_copiado():
    try:
        texto = pyperclip.paste()
        return texto if texto else ""
    except:
        return ""

def ler_arquivo(caminho):
    """üîß Fun√ß√£o corrigida que usa o m√©todo corrigido para BOM"""
    return ler_arquivo_corrigido_bom(caminho)

def mostrar_debug_texto(texto, nome):
    """üÜï Mostra informa√ß√µes detalhadas do texto incluindo an√°lise de \\r (v2.1.2)"""
    print(f"üìã {nome}:")
    print(f"   Tamanho: {len(texto)} caracteres")
    print(f"   Repr: {repr(texto[:100])}")
    print(f"   Hex: {' '.join(f'{ord(c):02x}' for c in texto[:20])}")
    
    # üÜï AN√ÅLISE ESPEC√çFICA DE CARRIAGE RETURNS
    detectar_problemas_carriage_return(texto)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üö® FUN√á√ÉO CORRIGIDA PARA C√ÅLCULO PRECISO DE POSI√á√ïES (CORRE√á√ÉO COMPLETA)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def calcular_posicoes_precisas(conteudo_original: str, texto_procurado: str, debug_arquivo: str = "", caminho_arquivo: str = "") -> Optional[Dict[str, int]]:
    """üîß Vers√£o CORRIGIDA v2.1.6 - Mapeamento preciso com quebras de linha diferentes"""
    if not texto_procurado or not conteudo_original:
        return None
    
    # üö® CR√çTICO: Detecta se arquivo original tinha BOM
    offset_bom = 0
    if caminho_arquivo and os.path.exists(caminho_arquivo):
        info_encoding = detectar_bom_e_encoding(caminho_arquivo)
        if info_encoding['has_bom'] and 'utf-8' in info_encoding['detected'].lower():
            offset_bom = info_encoding['bom_size']
            if debug_arquivo:
                print(f"üîñ BOM detectado: ajustando posi√ß√µes em +{offset_bom} bytes")
    
    if debug_arquivo:
        print(f"üîç Iniciando busca precisa em {debug_arquivo} (offset BOM: {offset_bom})")
        print(f"   üìä Conte√∫do: {len(conteudo_original)} chars")
        print(f"   üìä Procurado: {len(texto_procurado)} chars")
    
    # ESTRAT√âGIA 1: BUSCA DIRETA
    try:
        posicao_direta = conteudo_original.find(texto_procurado)
        if posicao_direta != -1:
            if debug_arquivo:
                print(f"‚úÖ ESTRAT√âGIA 1: Busca direta OK (pos: {posicao_direta} + BOM: {offset_bom})")
            return {
                'inicio': posicao_direta + offset_bom,  # üö® AJUSTE BOM
                'fim': posicao_direta + len(texto_procurado) + offset_bom  # üö® AJUSTE BOM
            }
    except Exception as e:
        if debug_arquivo:
            print(f"‚ùå ESTRAT√âGIA 1: Erro na busca direta: {e}")
    
    # ESTRAT√âGIA 2: NORMALIZA√á√ÉO DE QUEBRAS (MELHORADA v2.1.6)
    try:
        texto_norm = texto_procurado.replace('\r\n', '\n').replace('\r', '\n')
        conteudo_norm = conteudo_original.replace('\r\n', '\n').replace('\r', '\n')
        
        posicao_norm = conteudo_norm.find(texto_norm)
        if posicao_norm != -1:
            if debug_arquivo:
                print(f"üîß ESTRAT√âGIA 2: Normaliza√ß√£o OK (pos normalizada: {posicao_norm})")
            
            # üÜï MAPEAMENTO PRECISO: Posi√ß√£o normalizada ‚Üí original
            contador = 0
            pos_real = 0
            
            for i, char in enumerate(conteudo_original):
                if contador >= posicao_norm:
                    pos_real = i
                    break
                
                if char == '\r':
                    if i + 1 < len(conteudo_original) and conteudo_original[i + 1] == '\n':
                        # CRLF: pula \r (ser√° contado como \n no pr√≥ximo)
                        continue
                    else:
                        # CR isolado: conta como 1
                        contador += 1
                else:
                    contador += 1
            
            # üÜï CALCULA FIM BASEADO NO TAMANHO ORIGINAL DO TEXTO
            chars_mapeados = 0
            fim_real = pos_real
            
            for i in range(pos_real, len(conteudo_original)):
                if chars_mapeados >= len(texto_procurado):
                    break
                fim_real = i + 1
                chars_mapeados += 1
            
            if debug_arquivo:
                print(f"   üìç Pos real mapeada: {pos_real} at√© {fim_real}")
                print(f"   üîß Ajuste BOM: +{offset_bom}")
                
                # Valida√ß√£o do mapeamento
                texto_extraido = conteudo_original[pos_real:fim_real]
                texto_extraido_norm = texto_extraido.replace('\r\n', '\n').replace('\r', '\n')
                if texto_extraido_norm == texto_norm:
                    print(f"   ‚úÖ Mapeamento validado: textos id√™nticos ap√≥s normaliza√ß√£o")
                else:
                    print(f"   ‚ö†Ô∏è Mapeamento com diferen√ßas pequenas")
            
            return {
                'inicio': pos_real + offset_bom,  # üö® AJUSTE BOM
                'fim': fim_real + offset_bom      # üö® AJUSTE BOM
            }
    except Exception as e:
        if debug_arquivo:
            print(f"‚ùå ESTRAT√âGIA 2: Erro na normaliza√ß√£o: {e}")
    
    # ESTRAT√âGIA 3: BUSCA POR √ÇNCORAS (com ajuste BOM)
    try:
        linhas = [l.strip() for l in texto_procurado.split('\n') if l.strip()]
        if len(linhas) >= 2:
            primeira = linhas[0]
            ultima = linhas[-1]
            
            pos_primeira = conteudo_original.find(primeira)
            if pos_primeira != -1:
                pos_ultima = conteudo_original.find(ultima, pos_primeira + len(primeira))
                if pos_ultima != -1:
                    inicio = max(0, pos_primeira - 50)
                    fim = min(len(conteudo_original), pos_ultima + len(ultima) + 50)
                    regiao = conteudo_original[inicio:fim]
                    
                    pos_regiao = regiao.find(texto_procurado)
                    if pos_regiao != -1:
                        if debug_arquivo:
                            print(f"‚öì ESTRAT√âGIA 3: √Çncoras OK (+ BOM: {offset_bom})")
                        return {
                            'inicio': inicio + pos_regiao + offset_bom,  # üö® AJUSTE BOM
                            'fim': inicio + pos_regiao + len(texto_procurado) + offset_bom  # üö® AJUSTE BOM
                        }
    except Exception as e:
        if debug_arquivo:
            print(f"‚ùå ESTRAT√âGIA 3: Erro nas √¢ncoras: {e}")
    
    # ESTRAT√âGIA 4: STRIP
    try:
        texto_strip = texto_procurado.strip()
        if len(texto_strip) != len(texto_procurado):
            pos_strip = conteudo_original.find(texto_strip)
            if pos_strip != -1:
                if debug_arquivo:
                    print(f"‚úÇÔ∏è ESTRAT√âGIA 4: Strip OK (+ BOM: {offset_bom})")
                return {
                    'inicio': pos_strip + offset_bom,  # üö® AJUSTE BOM
                    'fim': pos_strip + len(texto_strip) + offset_bom  # üö® AJUSTE BOM
                }
    except Exception as e:
        if debug_arquivo:
            print(f"‚ùå ESTRAT√âGIA 4: Erro no strip: {e}")
    
    if debug_arquivo:
        print(f"‚ùå TODAS ESTRAT√âGIAS FALHARAM para {debug_arquivo}")
    
    return None

def validar_posicoes_com_bom(conteudo_original: str, posicoes: Dict[str, int], texto_esperado: str, caminho_arquivo: str, debug_arquivo: str = "") -> bool:
    """üÜï Valida posi√ß√µes considerando offset BOM"""
    # Detecta offset BOM
    offset_bom = 0
    if caminho_arquivo and os.path.exists(caminho_arquivo):
        info_encoding = detectar_bom_e_encoding(caminho_arquivo)
        if info_encoding['has_bom'] and 'utf-8' in info_encoding['detected'].lower():
            offset_bom = info_encoding['bom_size']
    
    # Remove offset BOM para validar no conte√∫do sem BOM
    inicio = posicoes['inicio'] - offset_bom
    fim = posicoes['fim'] - offset_bom
    
    # Verifica√ß√µes b√°sicas
    if inicio < 0 or fim > len(conteudo_original) or inicio >= fim:
        if debug_arquivo:
            print(f"‚ùå Valida√ß√£o FALHOU para {debug_arquivo}: limites inv√°lidos (ajustados para BOM: -{offset_bom})")
        return False
    
    # Extrai o texto nas posi√ß√µes calculadas
    texto_extraido = conteudo_original[inicio:fim]
    
    # üîç VALIDA√á√ÉO RIGOROSA
    if texto_extraido == texto_esperado:
        if debug_arquivo:
            print(f"‚úÖ Valida√ß√£o OK para {debug_arquivo}: textos id√™nticos (com ajuste BOM: +{offset_bom})")
        return True
    
    # üîß VALIDA√á√ÉO FLEX√çVEL PARA QUEBRAS DE LINHA
    texto_extraido_norm = texto_extraido.replace('\r\n', '\n')
    texto_esperado_norm = texto_esperado.replace('\r\n', '\n')
    
    if texto_extraido_norm == texto_esperado_norm:
        if debug_arquivo:
            print(f"‚úÖ Valida√ß√£o OK para {debug_arquivo}: textos id√™nticos ap√≥s normaliza√ß√£o (BOM: +{offset_bom})")
        return True
    
    # üÜï VALIDA√á√ÉO FLEX√çVEL PARA U+000D
    texto_extraido_sem_cr = limpar_carriage_returns(texto_extraido)
    texto_esperado_sem_cr = limpar_carriage_returns(texto_esperado)
    
    if texto_extraido_sem_cr == texto_esperado_sem_cr:
        if debug_arquivo:
            print(f"‚úÖ Valida√ß√£o OK para {debug_arquivo}: textos id√™nticos ap√≥s remover \\r (BOM: +{offset_bom})")
        return True
    
    if debug_arquivo:
        print(f"‚ùå Valida√ß√£o FALHOU para {debug_arquivo}: textos diferentes (mesmo com ajuste BOM: +{offset_bom})")
        print(f"   üìù Extra√≠do: {repr(texto_extraido[:50])}")
        print(f"   üìù Esperado: {repr(texto_esperado[:50])}")
    
    return False

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß FUN√á√ïES DE BUSCA ATUALIZADAS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def tipo1_comparacao_literal(texto_copiado):
    """TIPO 1: Compara√ß√£o 100% literal - NADA √© removido"""
    print("üîç TIPO 1: COMPARA√á√ÉO 100% LITERAL (v2.1.6 - CORRE√á√ÉO COMPLETA)")
    print("Regra: texto_copiado in conteudo_arquivo")
    
    for raiz, _, arquivos in os.walk(PASTA_BASE):
        for arquivo in arquivos:
            ext = os.path.splitext(arquivo)[1].lower()
            if ext in EXTENSOES_NEGADAS or eh_arquivo_backup(arquivo):
                continue
                
            caminho_arquivo = os.path.join(raiz, arquivo)
            conteudo = ler_arquivo(caminho_arquivo)
            
            if texto_copiado in conteudo:
                print(f"‚úÖ OK - {arquivo}")
                
                # üö® PASSA CAMINHO PARA CORRE√á√ÉO BOM
                posicoes = calcular_posicoes_precisas(conteudo, texto_copiado, arquivo, caminho_arquivo)
                if not posicoes:
                    print(f"‚ùå Erro ao calcular posi√ß√µes para {arquivo}")
                    continue
                
                if not validar_posicoes_com_bom(conteudo, posicoes, texto_copiado, caminho_arquivo, arquivo):
                    print(f"‚ùå Valida√ß√£o falhou para {arquivo}")
                    continue
                
                contexto_inicio = max(0, posicoes['inicio'] - 50)
                contexto_fim = min(len(conteudo) + 3, posicoes['fim'] + 50)  # +3 para BOM
                
                arquivo_info = {
                    'nome': arquivo,
                    'caminho': caminho_arquivo,
                    'inicio': posicoes['inicio'],
                    'fim': posicoes['fim'],
                    'tamanho': len(texto_copiado),
                    'texto_original': texto_copiado,
                    'contexto_inicio': contexto_inicio,
                    'contexto_fim': contexto_fim,
                    'contexto_texto': conteudo[max(0, contexto_inicio-3):contexto_fim-3]  # Ajuste contexto
                }
                
                adicionar_resultado_global(1, arquivo_info)
                return
    
    print("‚ùå FAIL")

def tipo2_comparacao_arquivo_completo(texto_copiado):
    """TIPO 2: Arquivo completo deve ser igual ao texto copiado"""
    print("üîç TIPO 2: ARQUIVO COMPLETO IGUAL AO TEXTO")
    print("Regra: texto_copiado == conteudo_arquivo")
    
    for raiz, _, arquivos in os.walk(PASTA_BASE):
        for arquivo in arquivos:
            ext = os.path.splitext(arquivo)[1].lower()
            if ext in EXTENSOES_NEGADAS or eh_arquivo_backup(arquivo):
                continue
                
            caminho_arquivo = os.path.join(raiz, arquivo)
            conteudo = ler_arquivo(caminho_arquivo)
            
            if texto_copiado == conteudo:
                print(f"‚úÖ OK - {arquivo}")
                
                arquivo_info = {
                    'nome': arquivo,
                    'caminho': caminho_arquivo,
                    'inicio': 0,
                    'fim': len(conteudo),
                    'tamanho': len(texto_copiado),
                    'texto_original': texto_copiado,
                    'contexto_inicio': 0,
                    'contexto_fim': len(conteudo),
                    'contexto_texto': conteudo
                }
                
                adicionar_resultado_global(2, arquivo_info)
                return
    
    print("‚ùå FAIL")

def tipo3_comparacao_quebras_normalizadas(texto_copiado):
    """üîß TIPO 3: Normaliza quebras de linha \\r\\n para \\n"""
    print("üîç TIPO 3: QUEBRAS DE LINHA NORMALIZADAS (v2.1.6 - CORRE√á√ÉO COMPLETA)")
    print("Regra: normaliza \\r\\n para \\n, depois texto_copiado in conteudo")
    
    texto_normalizado = texto_copiado.replace('\r\n', '\n')
    arquivos_encontrados = 0
    
    for raiz, _, arquivos in os.walk(PASTA_BASE):
        for arquivo in arquivos:
            ext = os.path.splitext(arquivo)[1].lower()
            if ext in EXTENSOES_NEGADAS or eh_arquivo_backup(arquivo):
                continue
                
            caminho_arquivo = os.path.join(raiz, arquivo)
            conteudo_original = ler_arquivo(caminho_arquivo)
            conteudo_normalizado = conteudo_original.replace('\r\n', '\n')
            
            if texto_normalizado in conteudo_normalizado:
                print(f"üîç Calculando posi√ß√µes precisas para {arquivo}...")
                
                # üö® PASSA CAMINHO PARA CORRE√á√ÉO BOM
                posicoes = calcular_posicoes_precisas(conteudo_original, texto_copiado, arquivo, caminho_arquivo)
                if not posicoes:
                    print(f"‚ùå Erro ao calcular posi√ß√µes para {arquivo}")
                    continue
                
                if not validar_posicoes_com_bom(conteudo_original, posicoes, texto_copiado, caminho_arquivo, arquivo):
                    print(f"‚ùå Valida√ß√£o falhou para {arquivo}")
                    continue
                
                contexto_inicio = max(0, posicoes['inicio'] - 50)
                contexto_fim = min(len(conteudo_original) + 3, posicoes['fim'] + 50)  # +3 para BOM
                contexto_texto = conteudo_original[max(0, contexto_inicio-3):contexto_fim-3]  # Ajuste contexto
                
                arquivo_info = {
                    'nome': arquivo,
                    'caminho': caminho_arquivo,
                    'inicio': posicoes['inicio'],
                    'fim': posicoes['fim'],
                    'tamanho': len(texto_copiado),
                    'texto_original': texto_copiado,
                    'contexto_inicio': contexto_inicio,
                    'contexto_fim': contexto_fim,
                    'contexto_texto': contexto_texto
                }
                
                adicionar_resultado_global(3, arquivo_info)
                arquivos_encontrados += 1
                print(f"‚úÖ ENCONTRADO - {arquivo}")
    
    if arquivos_encontrados > 0:
        print(f"\nüéØ RESUMO TIPO3: Texto encontrado em {arquivos_encontrados} arquivo(s)")
    else:
        print("‚ùå FAIL")

def tipo4_comparacao_strip_aplicado(texto_copiado):
    """TIPO 4: Remove espa√ßos do in√≠cio e fim (.strip())"""
    print("üîç TIPO 4: COM STRIP NAS PONTAS (v2.1.6 - CORRE√á√ÉO COMPLETA)")
    print("Regra: aplica .strip() em ambos, depois texto_copiado in conteudo")
    
    texto_stripped = texto_copiado.strip()
    
    for raiz, _, arquivos in os.walk(PASTA_BASE):
        for arquivo in arquivos:
            ext = os.path.splitext(arquivo)[1].lower()
            if ext in EXTENSOES_NEGADAS or eh_arquivo_backup(arquivo):
                continue
                
            caminho_arquivo = os.path.join(raiz, arquivo)
            conteudo = ler_arquivo(caminho_arquivo)
            conteudo_stripped = conteudo.strip()
            
            if texto_stripped in conteudo_stripped:
                print(f"‚úÖ OK - {arquivo}")
                
                # üö® PASSA CAMINHO PARA CORRE√á√ÉO BOM
                posicoes = calcular_posicoes_precisas(conteudo, texto_copiado, arquivo, caminho_arquivo)
                if not posicoes:
                    posicoes_stripped = calcular_posicoes_precisas(conteudo, texto_stripped, arquivo, caminho_arquivo)
                    if posicoes_stripped:
                        posicoes = posicoes_stripped
                    else:
                        print(f"‚ùå Erro ao calcular posi√ß√µes para {arquivo}")
                        continue
                
                contexto_inicio = max(0, posicoes['inicio'] - 50)
                contexto_fim = min(len(conteudo) + 3, posicoes['fim'] + 50)  # +3 para BOM
                
                arquivo_info = {
                    'nome': arquivo,
                    'caminho': caminho_arquivo,
                    'inicio': posicoes['inicio'],
                    'fim': posicoes['fim'],
                    'tamanho': len(texto_copiado),
                    'texto_original': texto_copiado,
                    'contexto_inicio': contexto_inicio,
                    'contexto_fim': contexto_fim,
                    'contexto_texto': conteudo[max(0, contexto_inicio-3):contexto_fim-3]  # Ajuste contexto
                }
                
                adicionar_resultado_global(4, arquivo_info)
                return
    
    print("‚ùå FAIL")

def calcular_similaridade_melhorada(texto1, texto2):
    """
    üîß ALGORITMO OTIMIZADO: Calcula similaridade mais precisa
    """
    def normalizar_texto(texto):
        linhas = []
        for linha in texto.split('\n'):
            linha_limpa = linha.strip()
            if linha_limpa:
                linhas.append(linha_limpa)
        return '\n'.join(linhas)
    
    texto1_norm = normalizar_texto(texto1)
    texto2_norm = normalizar_texto(texto2)
    
    if texto1_norm == texto2_norm:
        return 100.0
    if not texto1_norm or not texto2_norm:
        return 0.0
    
    # üéØ ALGORITMO MELHORADO: Combina m√∫ltiplas m√©tricas
    
    # 1. Similaridade de caracteres
    chars1 = set(texto1_norm.lower())
    chars2 = set(texto2_norm.lower())
    if chars1.union(chars2):
        sim_chars = len(chars1.intersection(chars2)) / len(chars1.union(chars2))
    else:
        sim_chars = 0
    
    # 2. Similaridade de palavras
    palavras1 = set(texto1_norm.lower().split())
    palavras2 = set(texto2_norm.lower().split())
    if palavras1.union(palavras2):
        sim_palavras = len(palavras1.intersection(palavras2)) / len(palavras1.union(palavras2))
    else:
        sim_palavras = 0
    
    # 3. Similaridade de tamanho
    tam_min = min(len(texto1_norm), len(texto2_norm))
    tam_max = max(len(texto1_norm), len(texto2_norm))
    sim_tamanho = tam_min / tam_max if tam_max > 0 else 0
    
    # 4. Bonus substring
    texto1_lower = texto1_norm.lower()
    texto2_lower = texto2_norm.lower()
    if texto1_lower in texto2_lower or texto2_lower in texto1_lower:
        bonus_substring = 0.3
    else:
        bonus_substring = 0
    
    # üèÜ F√ìRMULA FINAL
    similaridade_final = (
        sim_chars * 0.3 +
        sim_palavras * 0.4 +
        sim_tamanho * 0.2 +
        bonus_substring
    ) * 100
    
    return min(100.0, similaridade_final)

def extrair_ancoras(texto):
    """üÜï Extrai √¢ncoras TRIPLAS para busca por probabilidade (inicial, meio, final) - v2.1.1"""
    linhas = [linha.strip() for linha in texto.split('\n') if linha.strip()]
    
    if not linhas:
        return None, None, None
    
    if len(linhas) == 1:
        return linhas[0], linhas[0], linhas[0]
    
    if len(linhas) == 2:
        return linhas[0], linhas[0], linhas[1]  # inicial, inicial como meio, final
    
    # üéØ CALCULA POSI√á√ÉO DO MEIO (mais inteligente)
    indice_meio = len(linhas) // 2
    
    return linhas[0], linhas[indice_meio], linhas[-1]

def tipo5_busca_por_probabilidade(texto_copiado, limite_similaridade=90.0):
    """üÜï TIPO 5: Busca por probabilidade com CORRE√á√ÉO COMPLETA v2.1.6"""
    print("üîç TIPO 5: BUSCA POR PROBABILIDADE COM CORRE√á√ÉO COMPLETA")
    print(f"Regra: √Çncoras inicial/final + an√°lise TIPO3 na linha do meio, similaridade >= {limite_similaridade}%")
    
    ancora_inicial, ancora_meio, ancora_final = extrair_ancoras(texto_copiado)
    
    if not ancora_inicial:
        print("‚ùå ERRO: N√£o foi poss√≠vel extrair √¢ncoras do texto copiado")
        return
    
    print(f"üéØ √ÇNCORAS EXTRA√çDAS:")
    print(f"   üìç Inicial: {repr(ancora_inicial[:50])}")
    print(f"   üìç Meio (TIPO3): {repr(ancora_meio[:50])}")
    print(f"   üìç Final: {repr(ancora_final[:50])}")
    
    # üÜï PREPARA LINHA DO MEIO PARA AN√ÅLISE TIPO3
    linha_meio_normalizada = ancora_meio.replace('\r\n', '\n')
    print(f"üî¨ ESTRAT√âGIA MATEM√ÅTICA: Aplicando precis√£o TIPO3 na linha do meio")
    
    arquivos_encontrados = 0
    
    for raiz, _, arquivos in os.walk(PASTA_BASE):
        for arquivo in arquivos:
            ext = os.path.splitext(arquivo)[1].lower()
            if ext in EXTENSOES_NEGADAS or eh_arquivo_backup(arquivo):
                continue
                
            caminho_arquivo = os.path.join(raiz, arquivo)
            conteudo_original = ler_arquivo(caminho_arquivo)
            
            # 1. üîç BUSCA √ÇNCORA INICIAL (primeira valida√ß√£o)
            pos_inicial = conteudo_original.find(ancora_inicial)
            if pos_inicial == -1:
                continue  # √Çncora inicial n√£o encontrada
            
            # 2. üîç BUSCA √ÇNCORA FINAL (segunda valida√ß√£o)
            pos_busca_final = pos_inicial + len(ancora_inicial)
            pos_final_ancora = conteudo_original.find(ancora_final, pos_busca_final)
            
            if pos_final_ancora == -1:
                if ancora_inicial == ancora_final:
                    pos_final_ancora = pos_inicial
                else:
                    continue
            
            # 3. üÜï AN√ÅLISE MATEM√ÅTICA H√çBRIDA: TIPO3 na linha do meio
            score_matematico = 0
            bonus_tipo3_meio = 0
            bonus_ancora_meio = 0
            bonus_precisao = 0
            
            # Aplica TIPO3 especificamente na linha do meio
            conteudo_normalizado = conteudo_original.replace('\r\n', '\n')
            
            if linha_meio_normalizada in conteudo_normalizado:
                # üèÜ TIPO3 na linha do meio ENCONTRADO!
                pos_meio_tipo3 = conteudo_normalizado.find(linha_meio_normalizada)
                
                # Verifica se a linha do meio est√° dentro da regi√£o das √¢ncoras
                pos_inicial_normalizada = conteudo_normalizado.find(ancora_inicial.replace('\r\n', '\n'))
                pos_final_normalizada = conteudo_normalizado.find(ancora_final.replace('\r\n', '\n'), pos_inicial_normalizada + len(ancora_inicial))
                
                if pos_inicial_normalizada <= pos_meio_tipo3 <= pos_final_normalizada:
                    bonus_tipo3_meio = 35.0  # üéØ BONUS MATEM√ÅTICO: +35% por TIPO3 v√°lido no meio
                    score_matematico += bonus_tipo3_meio
                    print(f"üßÆ {arquivo}: TIPO3 na linha do meio CONFIRMADO! (+{bonus_tipo3_meio:.1f}% bonus)")
                    
                    # üÜï BONUS EXTRA: Se consegue validar posi√ß√µes precisas
                    posicoes_teste = calcular_posicoes_precisas(conteudo_original, texto_copiado, "", caminho_arquivo)
                    if posicoes_teste:
                        bonus_precisao = 25.0  # Bonus por posi√ß√µes v√°lidas
                        score_matematico += bonus_precisao
                        print(f"üéØ {arquivo}: Posi√ß√µes precisas validadas (+{bonus_precisao:.1f}% bonus de precis√£o)")
                else:
                    print(f"‚ö†Ô∏è {arquivo}: TIPO3 linha do meio encontrada, mas fora da regi√£o das √¢ncoras")
            else:
                print(f"üìä {arquivo}: Linha do meio n√£o passa no teste TIPO3")
            
            # 4. üéØ BUSCA √ÇNCORA DO MEIO TRADICIONAL (valida√ß√£o adicional)
            if ancora_meio != ancora_inicial and ancora_meio != ancora_final:
                pos_busca_meio_inicio = pos_inicial + len(ancora_inicial)
                pos_busca_meio_fim = pos_final_ancora
                trecho_busca_meio = conteudo_original[pos_busca_meio_inicio:pos_busca_meio_fim + len(ancora_final)]
                pos_meio_relativa = trecho_busca_meio.find(ancora_meio)
                
                if pos_meio_relativa != -1:
                    bonus_ancora_meio = 10.0  # Bonus menor por √¢ncora tradicional
                    score_matematico += bonus_ancora_meio
                    print(f"‚úÖ {arquivo}: √Çncora do meio tradicional encontrada (+{bonus_ancora_meio:.1f}% bonus)")
                else:
                    print(f"‚ö†Ô∏è {arquivo}: √Çncora do meio tradicional n√£o localizada")
            else:
                # üÜï CASO ESPECIAL: √Çncoras inicial/final iguais (coment√°rios repetitivos)
                if ancora_inicial == ancora_final:
                    # D√° bonus se a linha do meio √© diferente e espec√≠fica
                    if ancora_meio != ancora_inicial and len(ancora_meio.strip()) > 10:
                        bonus_ancora_meio = 20.0  # Bonus por linha do meio espec√≠fica
                        score_matematico += bonus_ancora_meio
                        print(f"üî• {arquivo}: Linha do meio espec√≠fica em bloco com bordas iguais (+{bonus_ancora_meio:.1f}% bonus)")
                    else:
                        print(f"üìù {arquivo}: √Çncoras inicial/final iguais (bordas de coment√°rio)")
                else:
                    print(f"üìù {arquivo}: √Çncora do meio igual √†s bordas (texto pequeno)")
            
            # 5. üéØ CALCULA POSI√á√ïES E SIMILARIDADE BASE
            inicio_trecho = pos_inicial
            fim_linha_final = conteudo_original.find('\n', pos_final_ancora + len(ancora_final))
            if fim_linha_final == -1:
                fim_linha_final = len(conteudo_original)
            
            fim_trecho = fim_linha_final
            trecho_encontrado = conteudo_original[inicio_trecho:fim_trecho]
            
            similaridade_base = calcular_similaridade_melhorada(texto_copiado, trecho_encontrado)
            
            # üÜï C√ÅLCULO FINAL MATEM√ÅTICO: Similaridade base + bonus matem√°tico
            similaridade_final = min(100.0, similaridade_base + score_matematico)
            
            print(f"üßÆ Testando {arquivo}:")
            print(f"   üìä Similaridade base: {similaridade_base:.1f}%")
            print(f"   üéØ Score matem√°tico: +{score_matematico:.1f}%")
            print(f"   üèÜ Similaridade final: {similaridade_final:.1f}%")
            
            # 6. ‚úÖ VALIDA√á√ÉO FINAL POR SIMILARIDADE MATEM√ÅTICA (CORRIGIDA v2.1.6)
            if similaridade_final >= limite_similaridade:
                posicoes_validadas = calcular_posicoes_precisas(conteudo_original, texto_copiado, arquivo, caminho_arquivo)
                
                if posicoes_validadas:
                    inicio_final = posicoes_validadas['inicio']
                    fim_final = posicoes_validadas['fim']
                    print(f"‚úÖ Posi√ß√µes validadas por busca direta para {arquivo}")
                    
                    # üÜï BONUS EXTRA: Se conseguiu validar posi√ß√µes precisas, √© muito confi√°vel
                    if bonus_precisao == 0:  # S√≥ adiciona se n√£o foi adicionado antes
                        similaridade_final = min(100.0, similaridade_final + 15.0)
                        print(f"üéØ {arquivo}: Bonus extra por valida√ß√£o precisa (+15.0% final)")
                else:
                    # üö® NOVO: Tenta busca com normaliza√ß√£o de quebras
                    print(f"‚ö†Ô∏è Busca direta falhou, tentando com normaliza√ß√£o de quebras...")
                    
                    # Normaliza quebras de linha
                    texto_normalizado = texto_copiado.replace('\r\n', '\n').replace('\r', '\n')
                    conteudo_normalizado = conteudo_original.replace('\r\n', '\n').replace('\r', '\n')
                    
                    # Busca no conte√∫do normalizado
                    pos_normalizada = conteudo_normalizado.find(texto_normalizado)
                    
                    if pos_normalizada != -1:
                        print(f"‚úÖ Encontrado ap√≥s normaliza√ß√£o na posi√ß√£o {pos_normalizada}")
                        
                        # Mapeia posi√ß√£o normalizada de volta para original
                        contador_norm = 0
                        pos_real = 0
                        
                        # Percorre o conte√∫do original contando caracteres
                        for i, char in enumerate(conteudo_original):
                            if contador_norm >= pos_normalizada:
                                pos_real = i
                                break
                            
                            # Se for \r\n, conta como 1 no normalizado
                            if char == '\r' and i + 1 < len(conteudo_original) and conteudo_original[i + 1] == '\n':
                                continue  # Pula o \r
                            
                            contador_norm += 1
                        
                        # Calcula fim baseado no tamanho original
                        fim_real = pos_real
                        chars_originais = 0
                        
                        # Conta caracteres do texto original no conte√∫do
                        for i in range(pos_real, len(conteudo_original)):
                            if chars_originais >= len(texto_copiado):
                                break
                            fim_real = i + 1
                            chars_originais += 1
                        
                        # Detecta BOM se houver
                        info_encoding = detectar_bom_e_encoding(caminho_arquivo)
                        offset_bom = info_encoding['bom_size'] if info_encoding['has_bom'] else 0
                        
                        inicio_final = pos_real + offset_bom
                        fim_final = fim_real + offset_bom
                        
                        print(f"üìç Posi√ß√µes calculadas: {inicio_final} at√© {fim_final}")
                        print(f"   üîß Offset BOM: +{offset_bom} bytes")
                        
                        # Valida√ß√£o
                        texto_validacao = conteudo_original[pos_real:fim_real]
                        texto_validacao_norm = texto_validacao.replace('\r\n', '\n').replace('\r', '\n')
                        
                        if texto_validacao_norm == texto_normalizado:
                            print(f"‚úÖ Valida√ß√£o OK: textos id√™nticos ap√≥s normaliza√ß√£o")
                        else:
                            print(f"‚ö†Ô∏è Valida√ß√£o parcial: pequenas diferen√ßas detectadas")
                            
                    else:
                        # √öltimo recurso: usa posi√ß√µes das √¢ncoras
                        print(f"‚ö†Ô∏è Usando posi√ß√µes por √¢ncoras (menos preciso)")
                        
                        # Detecta BOM para ajuste
                        info_encoding = detectar_bom_e_encoding(caminho_arquivo)
                        offset_bom = info_encoding['bom_size'] if info_encoding['has_bom'] else 0
                        
                        inicio_final = inicio_trecho + offset_bom
                        fim_final = fim_trecho + offset_bom
                        print(f"   üîß Ajuste BOM aplicado: +{offset_bom} bytes")
                
                # Contexto com ajuste para poss√≠vel BOM
                info_encoding = detectar_bom_e_encoding(caminho_arquivo)
                offset_contexto = info_encoding['bom_size'] if info_encoding['has_bom'] else 0
                
                contexto_inicio = max(0, inicio_final - 50)
                contexto_fim = min(len(conteudo_original) + offset_contexto, fim_final + 50)
                
                # Ajusta extra√ß√£o do contexto
                if offset_contexto > 0:
                    contexto_real_inicio = max(0, contexto_inicio - offset_contexto)
                    contexto_real_fim = min(len(conteudo_original), contexto_fim - offset_contexto)
                else:
                    contexto_real_inicio = contexto_inicio
                    contexto_real_fim = contexto_fim
                
                contexto_texto = conteudo_original[contexto_real_inicio:contexto_real_fim]
                
                arquivo_info = {
                    'nome': arquivo,
                    'caminho': caminho_arquivo,
                    'inicio': inicio_final,
                    'fim': fim_final,
                    'tamanho': len(texto_copiado),
                    'texto_original': texto_copiado,
                    'texto_encontrado': trecho_encontrado,
                    'similaridade': similaridade_final,
                    'contexto_inicio': contexto_inicio,
                    'contexto_fim': contexto_fim,
                    'contexto_texto': contexto_texto
                }
                
                adicionar_resultado_global(5, arquivo_info)
                arquivos_encontrados += 1
                print(f"‚úÖ MATCH MATEM√ÅTICO ENCONTRADO - {arquivo} ({similaridade_final:.1f}%)")
                print(f"   üßÆ Breakdown: {similaridade_base:.1f}% base + {score_matematico:.1f}% matem√°tico + valida√ß√µes")
    
    if arquivos_encontrados > 0:
        print(f"\nüéØ RESUMO TIPO5: Texto encontrado em {arquivos_encontrados} arquivo(s) por estrat√©gia matem√°tica h√≠brida")
        print(f"üßÆ Estrat√©gia: √Çncoras + TIPO3 no meio + c√°lculo matem√°tico de probabilidade")
    else:
        print("‚ùå FAIL: Nenhum arquivo atendeu o crit√©rio de estrat√©gia matem√°tica h√≠brida")

# üÜï TIPO 6: IGNORANDO TODOS OS U+000D (v2.1.2)
def tipo6_ignorar_carriage_returns(texto_copiado):
    """üÜï TIPO 6: Ignora completamente todos os U+000D (\\r) - HOTFIX v2.1.2"""
    print("üîç TIPO 6: IGNORANDO COMPLETAMENTE TODOS OS U+000D (\\r)")
    print("Regra: Remove todos os \\r de ambos os textos, depois busca")
    
    texto_sem_cr = limpar_carriage_returns(texto_copiado)
    arquivos_encontrados = 0
    
    print(f"üßπ TEXTO ORIGINAL: {len(texto_copiado)} chars")
    print(f"üßπ TEXTO LIMPO: {len(texto_sem_cr)} chars")
    print(f"üßπ CRs REMOVIDOS: {len(texto_copiado) - len(texto_sem_cr)}")
    
    for raiz, _, arquivos in os.walk(PASTA_BASE):
        for arquivo in arquivos:
            ext = os.path.splitext(arquivo)[1].lower()
            if ext in EXTENSOES_NEGADAS or eh_arquivo_backup(arquivo):
                continue
                
            caminho_arquivo = os.path.join(raiz, arquivo)
            conteudo_original = ler_arquivo(caminho_arquivo)
            conteudo_sem_cr = limpar_carriage_returns(conteudo_original)
            
            if texto_sem_cr in conteudo_sem_cr:
                print(f"üîç Calculando posi√ß√µes precisas para {arquivo} (TIPO6 - sem \\r)...")
                
                # üö® PASSA CAMINHO PARA CORRE√á√ÉO BOM
                posicoes = calcular_posicoes_precisas(conteudo_original, texto_copiado, arquivo, caminho_arquivo)
                if not posicoes:
                    print(f"‚ùå Erro ao calcular posi√ß√µes para {arquivo}")
                    continue
                
                # üîß USA FUN√á√ÉO CORRIGIDA COM BOM
                if not validar_posicoes_com_bom(conteudo_original, posicoes, texto_copiado, caminho_arquivo, arquivo):
                    print(f"‚ùå Valida√ß√£o falhou para {arquivo}")
                    continue
                
                contexto_inicio = max(0, posicoes['inicio'] - 50)
                contexto_fim = min(len(conteudo_original) + 3, posicoes['fim'] + 50)  # +3 para BOM
                contexto_texto = conteudo_original[max(0, contexto_inicio-3):contexto_fim-3]  # Ajuste contexto
                
                arquivo_info = {
                    'nome': arquivo,
                    'caminho': caminho_arquivo,
                    'inicio': posicoes['inicio'],
                    'fim': posicoes['fim'],
                    'tamanho': len(texto_copiado),
                    'texto_original': texto_copiado,
                    'contexto_inicio': contexto_inicio,
                    'contexto_fim': contexto_fim,
                    'contexto_texto': contexto_texto
                }
                
                adicionar_resultado_global(6, arquivo_info)
                arquivos_encontrados += 1
                print(f"‚úÖ ENCONTRADO - {arquivo} (ignorando \\r)")
    
    if arquivos_encontrados > 0:
        print(f"\nüéØ RESUMO TIPO6: Texto encontrado em {arquivos_encontrados} arquivo(s) ignorando todos os \\r")
    else:
        print("‚ùå FAIL")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üÜï SISTEMA CONSOLIDADO DE SALVAMENTO XML
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def salvar_xml_consolidado(resultados: List[ResultadoBusca]):
    """Fun√ß√£o unificada para salvar XML com resultados ordenados por confiabilidade"""
    if not resultados:
        print("‚ö†Ô∏è Nenhum resultado para salvar no XML")
        return
    
    resultados_ordenados = sorted(
        resultados,
        key=lambda r: (r.score_confiabilidade, r.similaridade or 0, r.nome_arquivo),
        reverse=True
    )
    
    print(f"\nüîÑ ORDENANDO RESULTADOS POR CONFIABILIDADE:")
    for i, resultado in enumerate(resultados_ordenados, 1):
        score = resultado.score_confiabilidade
        sim_texto = f" (sim: {resultado.similaridade:.1f}%)" if resultado.similaridade else ""
        print(f"   {i}. üìÅ {resultado.nome_arquivo} - TIPO{resultado.tipo} (score: {score:.1f}){sim_texto}")
    
    root = ET.Element("sessionlinner")
    
    info = ET.SubElement(root, "info")
    ET.SubElement(info, "timestamp").text = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    ET.SubElement(info, "versao").text = "2.1.6-CORRECAO-COMPLETA"
    ET.SubElement(info, "total_arquivos").text = str(len(resultados_ordenados))
    ET.SubElement(info, "tipos_busca_executados").text = ",".join(sorted(set(str(r.tipo) for r in resultados_ordenados)))
    ET.SubElement(info, "ordenacao").text = "score_confiabilidade DESC, similaridade DESC, nome ASC"
    
    # üÜï SALVA CONFIGURA√á√ïES DE QUALIDADE USADAS NA BUSCA (v2.1.1)
    configuracoes = ET.SubElement(info, "configuracoes_busca")
    ET.SubElement(configuracoes, "limite_probabilidade_melhor_resultado").text = str(LIMITE_PROBABILIDADE_MELHOR_RESULTADO)
    ET.SubElement(configuracoes, "limite_similaridade_tipo5").text = str(LIMITE_SIMILARIDADE_TIPO5)
    # üÜï ADICIONA INFO SOBRE HOTFIX U+000D (v2.1.2)
    ET.SubElement(configuracoes, "hotfix_carriage_return").text = "true"
    ET.SubElement(configuracoes, "tipo6_ignorar_cr").text = "true"
    # üö® NOVA INFO SOBRE CORRE√á√ÉO BOM
    ET.SubElement(configuracoes, "correcao_bom_utf8").text = "true"
    ET.SubElement(configuracoes, "encoding_automatico").text = "utf-8-sig"
    # üÜï NOVA CORRE√á√ÉO v2.1.6
    ET.SubElement(configuracoes, "correcao_quebras_linha").text = "true"
    ET.SubElement(configuracoes, "mapeamento_posicoes_preciso").text = "true"
    
    for i, resultado in enumerate(resultados_ordenados, 1):
        arquivo_elem = ET.SubElement(root, f"arquivo{i}")
        
        ET.SubElement(arquivo_elem, "nome").text = resultado.nome_arquivo
        ET.SubElement(arquivo_elem, "caminho_completo").text = resultado.caminho_completo
        
        confiabilidade = ET.SubElement(arquivo_elem, "confiabilidade")
        ET.SubElement(confiabilidade, "tipo_busca").text = str(resultado.tipo)
        ET.SubElement(confiabilidade, "score_confiabilidade").text = f"{resultado.score_confiabilidade:.2f}"
        if resultado.similaridade is not None:
            ET.SubElement(confiabilidade, "similaridade_percentual").text = f"{resultado.similaridade:.2f}"
        
        posicoes = ET.SubElement(arquivo_elem, "posicoes")
        ET.SubElement(posicoes, "inicio").text = str(resultado.posicao_inicio)
        ET.SubElement(posicoes, "fim").text = str(resultado.posicao_fim)
        ET.SubElement(posicoes, "tamanho_texto").text = str(resultado.tamanho_texto)
        
        validacao = ET.SubElement(posicoes, "validacao")
        ET.SubElement(validacao, "posicoes_validadas").text = "true"
        ET.SubElement(validacao, "metodo_calculo").text = "calcular_posicoes_precisas_v2_1_6_CORRECAO_COMPLETA"
        ET.SubElement(validacao, "hotfix_carriage_return").text = "aplicado"
        ET.SubElement(validacao, "correcao_bom_utf8").text = "aplicado"
        ET.SubElement(validacao, "mapeamento_quebras_linha").text = "aplicado"
        
        texto_elem = ET.SubElement(arquivo_elem, "texto_encontrado")
        ET.SubElement(texto_elem, "original").text = resultado.texto_original
        ET.SubElement(texto_elem, "repr_original").text = repr(resultado.texto_original)
        if resultado.texto_encontrado:
            ET.SubElement(texto_elem, "encontrado").text = resultado.texto_encontrado
            ET.SubElement(texto_elem, "repr_encontrado").text = repr(resultado.texto_encontrado)
        
        contexto = ET.SubElement(arquivo_elem, "contexto")
        ET.SubElement(contexto, "inicio_contexto").text = str(resultado.contexto_inicio)
        ET.SubElement(contexto, "fim_contexto").text = str(resultado.contexto_fim)
        ET.SubElement(contexto, "texto_contexto").text = resultado.contexto_texto
    
    try:
        tree = ET.ElementTree(root)
        ET.indent(tree, space="  ", level=0)
        tree.write("sessionlinner.xml", encoding="utf-8", xml_declaration=True)
        
        print(f"\nüíæ XML CONSOLIDADO SALVO COM SUCESSO!")
        print(f"   üìÅ Arquivo: sessionlinner.xml")
        print(f"   üìä Total de resultados: {len(resultados_ordenados)}")
        print(f"   üÜï Vers√£o: 2.1.6-CORRECAO-COMPLETA (quebras de linha + BOM)")
        
        # üÜï CONTROLE DE QUALIDADE: S√≥ mostra como "melhor resultado" se atender crit√©rio de probabilidade (v2.1.1)
        melhor_resultado = resultados_ordenados[0]
        probabilidade_melhor = melhor_resultado.similaridade if melhor_resultado.similaridade is not None else 100.0
        
        if probabilidade_melhor >= LIMITE_PROBABILIDADE_MELHOR_RESULTADO:
            print(f"   üèÜ Melhor resultado: {melhor_resultado.nome_arquivo} (TIPO{melhor_resultado.tipo}, score: {melhor_resultado.score_confiabilidade:.1f}, prob: {probabilidade_melhor:.1f}%)")
        else:
            print(f"   üìä Primeiro resultado: {melhor_resultado.nome_arquivo} (TIPO{melhor_resultado.tipo}, score: {melhor_resultado.score_confiabilidade:.1f}, prob: {probabilidade_melhor:.1f}%)")
            print(f"   ‚ö†Ô∏è Aviso: Probabilidade {probabilidade_melhor:.1f}% < {LIMITE_PROBABILIDADE_MELHOR_RESULTADO:.1f}% (limite m√≠nimo para 'melhor resultado')")
        
    except Exception as e:
        print(f"‚ùå ERRO ao salvar XML consolidado: {e}")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß FUN√á√ÉO DE LEITURA XML
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def ler_xml_posicoes(arquivo_especifico=None):
    """L√™ XML e sempre retorna o de MAIOR SCORE"""
    if not os.path.exists("sessionlinner.xml"):
        print("‚ùå ERRO: Arquivo sessionlinner.xml n√£o encontrado!")
        print("   Execute primeiro: python pythonsearch.py (sem par√¢metros)")
        return None
    
    try:
        tree = ET.parse("sessionlinner.xml")
        root = tree.getroot()
        
        versao_elem = root.find('info/versao')
        versao = versao_elem.text if versao_elem is not None else "anterior"
        print(f"üìã Carregando XML vers√£o: {versao}")
        
        # üÜï VERIFICA SE TEM HOTFIX U+000D (v2.1.2)
        hotfix_elem = root.find('info/configuracoes_busca/hotfix_carriage_return')
        if hotfix_elem is not None and hotfix_elem.text == "true":
            print("üîß XML com HOTFIX U+000D ativado")
        else:
            print("‚ö†Ô∏è XML sem HOTFIX U+000D (vers√£o anterior)")
        
        # üö® VERIFICA CORRE√á√ÉO BOM
        bom_elem = root.find('info/configuracoes_busca/correcao_bom_utf8')
        if bom_elem is not None and bom_elem.text == "true":
            print("üîß XML com CORRE√á√ÉO BOM UTF-8 ativada")
        else:
            print("‚ö†Ô∏è XML sem corre√ß√£o BOM (vers√£o anterior)")
        
        # üÜï VERIFICA CORRE√á√ÉO QUEBRAS v2.1.6
        quebras_elem = root.find('info/configuracoes_busca/correcao_quebras_linha')
        if quebras_elem is not None and quebras_elem.text == "true":
            print("üîß XML com CORRE√á√ÉO QUEBRAS DE LINHA ativada")
        else:
            print("‚ö†Ô∏è XML sem corre√ß√£o quebras de linha (vers√£o anterior)")
        
        # üÜï INFO SOBRE FILTRO DE BACKUP (v2.1.4)
        if versao in ['2.1.4', '2.1.4-CORRECAO-BOM', '2.1.6-CORRECAO-COMPLETA']:
            print("üóÇÔ∏è Filtro de arquivos de backup ativado")
        
        # üÜï L√ä CONFIGURA√á√ïES DE QUALIDADE SALVAS NO XML (v2.1.1)
        limite_probabilidade_xml = None
        limite_prob_elem = root.find('info/configuracoes_busca/limite_probabilidade_melhor_resultado')
        if limite_prob_elem is not None:
            limite_probabilidade_xml = float(limite_prob_elem.text)
            print(f"üéØ Limite de probabilidade usado na busca: {limite_probabilidade_xml:.1f}%")
            if limite_probabilidade_xml != LIMITE_PROBABILIDADE_MELHOR_RESULTADO:
                print(f"‚ö†Ô∏è Aviso: Limite atual ({LIMITE_PROBABILIDADE_MELHOR_RESULTADO:.1f}%) difere do usado na busca ({limite_probabilidade_xml:.1f}%)")
        else:
            limite_probabilidade_xml = LIMITE_PROBABILIDADE_MELHOR_RESULTADO  # Fallback para XMLs antigos
        
        if arquivo_especifico:
            print(f"üîç BUSCANDO ARQUIVO ESPEC√çFICO: {arquivo_especifico}")
            
            melhor_resultado = None
            melhor_score = -1
            
            for i in range(1, 21):
                arquivo_elem = root.find(f'arquivo{i}')
                if arquivo_elem is None:
                    continue
                
                nome_arquivo = arquivo_elem.find('nome').text
                if nome_arquivo == arquivo_especifico:
                    score_elem = arquivo_elem.find('confiabilidade/score_confiabilidade')
                    score = float(score_elem.text) if score_elem is not None else 0
                    
                    if score > melhor_score:
                        melhor_score = score
                        
                        similaridade_elem = arquivo_elem.find('confiabilidade/similaridade_percentual') or arquivo_elem.find('similaridade_percentual')
                        similaridade = float(similaridade_elem.text) if similaridade_elem is not None else None
                        
                        melhor_resultado = {
                            'arquivo': nome_arquivo,
                            'caminho': arquivo_elem.find('caminho_completo').text,
                            'inicio': int(arquivo_elem.find('posicoes/inicio').text),
                            'fim': int(arquivo_elem.find('posicoes/fim').text),
                            'timestamp': root.find('info/timestamp').text,
                            'similaridade': similaridade,
                            'score': score,
                            'tipo': arquivo_elem.find('confiabilidade/tipo_busca').text if arquivo_elem.find('confiabilidade/tipo_busca') is not None else "?",
                            'limite_probabilidade_busca': limite_probabilidade_xml,  # üÜï Passa o limite usado na busca
                            'versao': versao
                        }
            
            if melhor_resultado:
                print("üìã MELHOR RESULTADO ENCONTRADO (ARQUIVO ESPEC√çFICO):")
                print(f"   üìÅ Arquivo: {melhor_resultado['arquivo']}")
                print(f"   üìç Posi√ß√£o: {melhor_resultado['inicio']} at√© {melhor_resultado['fim']}")
                print(f"   üèÜ Score: {melhor_resultado['score']:.1f} (TIPO{melhor_resultado['tipo']})")
                if melhor_resultado['similaridade']:
                    print(f"   üéØ Similaridade: {melhor_resultado['similaridade']:.1f}%")
                    # üÜï CONTROLE DE QUALIDADE: Usa limite da busca original (v2.1.1)
                    limite_usado = melhor_resultado.get('limite_probabilidade_busca', limite_probabilidade_xml)
                    if melhor_resultado['similaridade'] < limite_usado:
                        print(f"   ‚ö†Ô∏è Aviso: Probabilidade {melhor_resultado['similaridade']:.1f}% < {limite_usado:.1f}% (abaixo do limite usado na busca)")
                print(f"   üïí Salvo em: {melhor_resultado['timestamp']}")
                return melhor_resultado
            
            print(f"‚ùå ERRO: Arquivo '{arquivo_especifico}' n√£o encontrado no XML!")
            print("üìã ARQUIVOS DISPON√çVEIS:")
            for i in range(1, 21):
                arquivo_elem = root.find(f'arquivo{i}')
                if arquivo_elem is not None:
                    nome = arquivo_elem.find('nome').text
                    score_elem = arquivo_elem.find('confiabilidade/score_confiabilidade')
                    score_texto = f" (score: {float(score_elem.text):.1f})" if score_elem is not None else ""
                    print(f"   {i}. üìÅ {nome}{score_texto}")
            return None
        
        arquivo_elem = root.find('arquivo1')
        if arquivo_elem is None:
            print("‚ùå ERRO: Nenhum arquivo encontrado no XML!")
            return None
        
        score_elem = arquivo_elem.find('confiabilidade/score_confiabilidade')
        score = float(score_elem.text) if score_elem is not None else 0
        
        tipo_elem = arquivo_elem.find('confiabilidade/tipo_busca')
        tipo = tipo_elem.text if tipo_elem is not None else "?"
        
        similaridade_elem = arquivo_elem.find('confiabilidade/similaridade_percentual') or arquivo_elem.find('similaridade_percentual')
        similaridade = float(similaridade_elem.text) if similaridade_elem is not None else None
        
        info = {
            'arquivo': arquivo_elem.find('nome').text,
            'caminho': arquivo_elem.find('caminho_completo').text,
            'inicio': int(arquivo_elem.find('posicoes/inicio').text),
            'fim': int(arquivo_elem.find('posicoes/fim').text),
            'timestamp': root.find('info/timestamp').text,
            'similaridade': similaridade,
            'score': score,
            'tipo': tipo,
            'limite_probabilidade_busca': limite_probabilidade_xml,  # üÜï Passa o limite usado na busca
            'versao': versao
        }
        
        print("üìã RESULTADO DE MAIOR CONFIABILIDADE CARREGADO:")
        print(f"   üìÅ Arquivo: {info['arquivo']}")
        print(f"   üìç Posi√ß√£o: {info['inicio']} at√© {info['fim']}")
        print(f"   üèÜ Score: {info['score']:.1f} (TIPO{info['tipo']})")
        if similaridade:
            print(f"   üéØ Similaridade: {similaridade:.1f}%")
            # üÜï CONTROLE DE QUALIDADE: Usa limite da busca original (v2.1.1)
            if similaridade < limite_probabilidade_xml:
                print(f"   ‚ö†Ô∏è Aviso: Probabilidade {similaridade:.1f}% < {limite_probabilidade_xml:.1f}% (abaixo do limite usado na busca)")
        print(f"   üïí Salvo em: {info['timestamp']}")
        
        return info
        
    except Exception as e:
        print(f"‚ùå ERRO ao ler XML: {e}")
        return None

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß FUN√á√ÉO PASTE CORRIGIDA v2.1.6
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def colar_nas_coordenadas(arquivo_especifico=None):
    """Cola o conte√∫do do Ctrl+C nas coordenadas salvas com CORRE√á√ÉO AUTOM√ÅTICA v2.1.6"""
    if arquivo_especifico:
        print(f"üìã MODO PASTE ESPEC√çFICO: {arquivo_especifico}")
    else:
        print("üìã MODO PASTE: Colando nas coordenadas salvas")
    print("=" * 80)
    
    posicoes = ler_xml_posicoes(arquivo_especifico)
    if not posicoes:
        return
    
    texto_novo = obter_texto_copiado()
    if not texto_novo:
        print("‚ùå ERRO: Nenhum texto na √°rea de transfer√™ncia para colar!")
        return
    
    print(f"\nüìù TEXTO A SER COLADO:")
    mostrar_debug_texto(texto_novo, "NOVO CONTE√öDO")
    
    # üÜï DETECTA PROBLEMAS COM U+000D NO TEXTO NOVO (v2.1.2)
    tem_problemas_cr = detectar_problemas_carriage_return(texto_novo)
    if tem_problemas_cr:
        print("‚ö†Ô∏è AVISO: Texto cont√©m carriage returns isolados (\\r)")
        print("   Recomenda-se executar nova busca com TIPO6 se houver problemas")
    
    if not os.path.exists(posicoes['caminho']):
        print(f"‚ùå ERRO: Arquivo n√£o encontrado: {posicoes['caminho']}")
        return
    
    try:
        # üö® CORRE√á√ÉO: Usa leitura corrigida com BOM
        conteudo_original = ler_arquivo(posicoes['caminho'])
        
        print(f"\nüìÅ ARQUIVO CARREGADO: {posicoes['arquivo']}")
        print(f"   üìè Tamanho original: {len(conteudo_original)} caracteres")
        print(f"   üîß XML vers√£o: {posicoes.get('versao', 'anterior')}")
        
        # üö® CORRE√á√ÉO AUTOM√ÅTICA DE COORDENADAS v2.1.6
        info_encoding = detectar_bom_e_encoding(posicoes['caminho'])
        offset_bom = info_encoding['bom_size'] if info_encoding['has_bom'] else 0
        
        # Ajusta coordenadas removendo offset BOM (pois conte√∫do foi lido sem BOM)
        inicio_ajustado = posicoes['inicio'] - offset_bom
        fim_ajustado = posicoes['fim'] - offset_bom
        
        print(f"\nüîß AJUSTE DE COORDENADAS:")
        print(f"   üìç Coordenadas XML: {posicoes['inicio']} at√© {posicoes['fim']}")
        print(f"   üîñ Offset BOM: {offset_bom} bytes")
        print(f"   üìç Coordenadas ajustadas: {inicio_ajustado} at√© {fim_ajustado}")
        
        # Verifica se o texto nas posi√ß√µes bate com o esperado
        deve_buscar = False
        
        if inicio_ajustado < 0 or fim_ajustado > len(conteudo_original) or inicio_ajustado >= fim_ajustado:
            print(f"‚ö†Ô∏è Coordenadas fora dos limites v√°lidos")
            deve_buscar = True
        else:
            texto_atual_posicoes = conteudo_original[inicio_ajustado:fim_ajustado]
            
            if not texto_atual_posicoes or len(texto_atual_posicoes) != len(texto_novo):
                print(f"‚ö†Ô∏è Tamanhos diferentes: atual={len(texto_atual_posicoes)}, novo={len(texto_novo)}")
                deve_buscar = True
            else:
                # Compara normalizando quebras
                texto_atual_norm = texto_atual_posicoes.replace('\r\n', '\n').replace('\r', '\n')
                texto_novo_norm = texto_novo.replace('\r\n', '\n').replace('\r', '\n')
                
                if texto_atual_norm != texto_novo_norm:
                    print(f"‚ö†Ô∏è Conte√∫dos diferentes ap√≥s normaliza√ß√£o")
                    deve_buscar = True
        
        if deve_buscar:
            print(f"\nüîç BUSCANDO POSI√á√ÉO CORRETA (coordenadas podem estar desatualizadas)...")
            
            # Tenta busca direta primeiro
            pos_direta = conteudo_original.find(texto_novo)
            
            if pos_direta == -1:
                # Tenta com normaliza√ß√£o
                texto_novo_norm = texto_novo.replace('\r\n', '\n').replace('\r', '\n')
                conteudo_norm = conteudo_original.replace('\r\n', '\n').replace('\r', '\n')
                pos_norm = conteudo_norm.find(texto_novo_norm)
                
                if pos_norm != -1:
                    print(f"‚úÖ Encontrado ap√≥s normaliza√ß√£o na posi√ß√£o {pos_norm}")
                    
                    # Mapeia de volta para original
                    contador = 0
                    for i, char in enumerate(conteudo_original):
                        if contador >= pos_norm:
                            pos_direta = i
                            break
                        if char == '\r' and i + 1 < len(conteudo_original) and conteudo_original[i + 1] == '\n':
                            continue
                        contador += 1
            
            if pos_direta != -1:
                inicio_ajustado = pos_direta
                fim_ajustado = pos_direta + len(texto_novo)
                print(f"‚úÖ POSI√á√ÉO CORRETA ENCONTRADA: {inicio_ajustado} at√© {fim_ajustado}")
                print(f"   üìä Diferen√ßa das coordenadas XML: {inicio_ajustado - (posicoes['inicio'] - offset_bom)} chars")
            else:
                print(f"‚ùå AVISO: N√£o foi poss√≠vel encontrar o texto exato no arquivo!")
                print(f"   Continuando com coordenadas do XML (podem estar incorretas)")
        
        # Usa as coordenadas ajustadas
        inicio = inicio_ajustado
        fim = fim_ajustado
        
        if inicio < 0 or fim > len(conteudo_original) or inicio >= fim:
            print(f"‚ùå ERRO: Coordenadas inv√°lidas!")
            print(f"   üìç In√≠cio: {inicio}, Fim: {fim}")
            print(f"   üìè Tamanho do arquivo: {len(conteudo_original)}")
            return
        
        texto_atual_nas_posicoes = conteudo_original[inicio:fim]
        print(f"\nüîç VALIDA√á√ÉO DAS POSI√á√ïES:")
        print(f"   üìç Posi√ß√µes: {inicio} ‚Üí {fim}")
        print(f"   üìè Tamanho esperado: {fim - inicio} caracteres")
        print(f"   üìè Texto atual nessas posi√ß√µes: {len(texto_atual_nas_posicoes)} caracteres")
        print(f"   üìã Conte√∫do atual: {repr(texto_atual_nas_posicoes[:100])}")
        
        # üÜï VALIDA√á√ÉO EXTRA COM HOTFIX U+000D (v2.1.2)
        if posicoes.get('versao') in ['2.1.2', '2.1.3', '2.1.4', '2.1.4-CORRECAO-BOM', '2.1.6-CORRECAO-COMPLETA']:
            print("üîß VALIDA√á√ÉO COM CORRE√á√ïES APLICADAS:")
            texto_atual_sem_cr = limpar_carriage_returns(texto_atual_nas_posicoes)
            texto_novo_sem_cr = limpar_carriage_returns(texto_novo)
            if texto_atual_sem_cr == texto_novo_sem_cr:
                print("   ‚úÖ Textos id√™nticos ap√≥s remover \\r (CORRE√á√ïES validadas)")
            else:
                # Tenta valida√ß√£o com normaliza√ß√£o
                texto_atual_norm = texto_atual_nas_posicoes.replace('\r\n', '\n').replace('\r', '\n')
                texto_novo_norm = texto_novo.replace('\r\n', '\n').replace('\r', '\n')
                if texto_atual_norm == texto_novo_norm:
                    print("   ‚úÖ Textos id√™nticos ap√≥s normalizar quebras (CORRE√á√ïES validadas)")
                else:
                    print("   ‚ö†Ô∏è Textos diferentes mesmo ap√≥s corre√ß√µes")
        
        texto_antigo = conteudo_original[inicio:fim]
        print(f"\nüîÑ SUBSTITUI√á√ÉO:")
        print(f"   üìç Posi√ß√µes: {inicio} ‚Üí {fim}")
        print(f"   üìè Tamanho antigo: {len(texto_antigo)} caracteres")
        print(f"   üìè Tamanho novo: {len(texto_novo)} caracteres")
        print(f"   ‚ùå Texto antigo: {repr(texto_antigo[:100])}")
        print(f"   ‚úÖ Texto novo: {repr(texto_novo[:100])}")
        
        texto_novo_final = texto_novo
        novo_conteudo = conteudo_original[:inicio] + texto_novo_final + conteudo_original[fim:]
        
        # üö® CORRE√á√ÉO: Salva com encoding UTF-8 sem BOM (padr√£o)
        with open(posicoes['caminho'], 'w', encoding='utf-8', newline='') as f:
            f.write(novo_conteudo)
        
        print(f"\n‚úÖ PASTE REALIZADO COM SUCESSO!")
        print(f"   üìÅ Arquivo: {posicoes['arquivo']}")
        print(f"   üìè Novo tamanho: {len(novo_conteudo)} caracteres")
        print(f"   üìù Diferen√ßa: {len(novo_conteudo) - len(conteudo_original):+d} caracteres")
        
        # Verifica√ß√£o usando leitura corrigida
        conteudo_verificacao = ler_arquivo(posicoes['caminho'])
        
        if len(conteudo_verificacao) == len(novo_conteudo):
            print("‚úÖ Verifica√ß√£o: Arquivo salvo corretamente!")
            
            texto_verificacao = conteudo_verificacao[inicio:inicio + len(texto_novo)]
            if texto_verificacao == texto_novo:
                print("‚úÖ Verifica√ß√£o final: Texto colado exatamente na posi√ß√£o correta!")
            else:
                print("‚ö†Ô∏è Aviso: Texto pode ter sido colado com pequenos ajustes de formata√ß√£o")
        else:
            print("‚ö†Ô∏è Aviso: Tamanho do arquivo diferente do esperado ap√≥s salvamento")
        
    except Exception as e:
        print(f"‚ùå ERRO ao processar arquivo: {e}")
        import traceback
        traceback.print_exc()

def criar_backup_antes_paste(caminho_arquivo):
    """Cria backup do arquivo antes de fazer modifica√ß√µes no modo paste com verifica√ß√£o de timezone"""
    try:
        if not os.path.exists(caminho_arquivo):
            print(f"‚ùå ERRO: Arquivo n√£o encontrado para backup: {caminho_arquivo}")
            return False
        
        diretorio_arquivo = os.path.dirname(caminho_arquivo)
        nome_arquivo = os.path.basename(caminho_arquivo)
        
        pasta_backup = os.path.join(diretorio_arquivo, "Backup")
        if not os.path.exists(pasta_backup):
            os.makedirs(pasta_backup)
            print(f"üìÅ Pasta Backup criada: {pasta_backup}")
        
        # üÜï OBTER INFORMA√á√ïES DE TEMPO DO ARQUIVO ORIGINAL
        stat_original = os.stat(caminho_arquivo)
        mtime_original = datetime.fromtimestamp(stat_original.st_mtime)
        
        temp_backup = os.path.join(pasta_backup, f"{nome_arquivo}.temp.bak")
        shutil.copy2(caminho_arquivo, temp_backup)
        
        # üÜï TIMESTAMP SINCRONIZADO COM VERIFICA√á√ÉO DE TIMEZONE
        import time
        agora = datetime.now()
        agora_real = datetime.fromtimestamp(time.time())  # For√ßa timestamp real do sistema
        timestamp = agora_real.strftime("%Y-%m-%d_%H-%M-%S")
        
        # üÜï DIAGN√ìSTICO DE SINCRONIZA√á√ÉO
        diferenca_datetime = abs((agora - agora_real).total_seconds())
        if diferenca_datetime > 5:
            print(f"‚ö†Ô∏è DETECTADA DIFEREN√áA DE {diferenca_datetime:.0f}s entre datetime.now() e time.time()")
            print(f"   üïí datetime.now(): {agora.strftime('%H:%M:%S')}")
            print(f"   üïí time.time(): {agora_real.strftime('%H:%M:%S')}")
        
        nome_backup = f"{nome_arquivo}.backup_{timestamp}.bak"
        caminho_backup = os.path.join(pasta_backup, nome_backup)
        
        os.rename(temp_backup, caminho_backup)
        
        # üÜï PRESERVAR TIMESTAMPS DO ARQUIVO ORIGINAL NO BACKUP
        os.utime(caminho_backup, (stat_original.st_atime, stat_original.st_mtime))
        
        # üÜï VERIFICA√á√ÉO DE TIMEZONE E RELAT√ìRIO DETALHADO
        stat_backup = os.stat(caminho_backup)
        mtime_backup = datetime.fromtimestamp(stat_backup.st_mtime)
        diferenca_horas = abs((agora - mtime_original).total_seconds() / 3600)
        
        print(f"üíæ BACKUP CRIADO:")
        print(f"   üìÅ Original: {nome_arquivo}")
        print(f"   üíæ Backup: {nome_backup}")
        print(f"   üìÇ Local: {pasta_backup}")
        print(f"   üïí VERIFICA√á√ÉO DE TIMESTAMP:")
        print(f"      üìÖ Arquivo original: {mtime_original.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"      üìÖ Backup criado: {agora.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"      üìÖ Backup preservado: {mtime_backup.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"      ‚è∞ Diferen√ßa temporal: {diferenca_horas:.1f} horas")
        
        # üÜï ALERTA PARA PROBLEMAS DE TIMEZONE
        if diferenca_horas > 3:
            print(f"   ‚ö†Ô∏è AVISO: Diferen√ßa de {diferenca_horas:.1f}h pode indicar problema de timezone")
            print(f"   üîß Sistema detectou poss√≠vel diferen√ßa de fuso hor√°rio")
        else:
            print(f"   ‚úÖ Timestamps consistentes (diferen√ßa: {diferenca_horas:.1f}h)")
        
        return True
        
    except Exception as e:
        print(f"‚ùå ERRO ao criar backup: {e}")
        import traceback
        traceback.print_exc()
        return False

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üÜï MODO BUSCA ATUALIZADO (v2.1.6)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def modo_busca():
    """Modo busca com consolida√ß√£o global de resultados e CORRE√á√ÉO COMPLETA v2.1.6"""
    print("üöÄ CTRLCSEARCH.PY v2.1.6 - CORRE√á√ÉO COMPLETA QUEBRAS DE LINHA")
    print("=" * 80)
    
    texto_copiado = obter_texto_copiado()
    
    if not texto_copiado:
        print("‚ùå ERRO: Nenhum texto na √°rea de transfer√™ncia!")
        return
    
    limpar_resultados_globais()
    mostrar_debug_texto(texto_copiado, "TEXTO COPIADO")
    
    # üÜï AN√ÅLISE INICIAL DE CARRIAGE RETURNS (v2.1.2)
    tem_problemas_cr = detectar_problemas_carriage_return(texto_copiado)
    if tem_problemas_cr:
        print("üîß HOTFIX U+000D: Detectados carriage returns isolados!")
        print("   TIPO6 ser√° executado para tratamento espec√≠fico")
    
    print("\n" + "=" * 80)
    tipo1_comparacao_literal(texto_copiado)
    
    print("\n" + "=" * 80)
    tipo2_comparacao_arquivo_completo(texto_copiado)
    
    print("\n" + "=" * 80)
    tipo3_comparacao_quebras_normalizadas(texto_copiado)
    
    print("\n" + "=" * 80)
    tipo4_comparacao_strip_aplicado(texto_copiado)
    
    print("\n" + "=" * 80)
    tipo5_busca_por_probabilidade(texto_copiado, limite_similaridade=LIMITE_SIMILARIDADE_TIPO5)
    
    # üÜï TIPO 6: HOTFIX PARA U+000D (v2.1.2)
    print("\n" + "=" * 80)
    tipo6_ignorar_carriage_returns(texto_copiado)
    
    print("\n" + "=" * 80)
    print("üèÅ AN√ÅLISE COMPLETA FINALIZADA (v2.1.6 - CORRE√á√ÉO COMPLETA)")
    
    if resultados_globais:
        print(f"\nüìä TOTAL DE RESULTADOS COLETADOS: {len(resultados_globais)}")
        print("üîÑ Iniciando consolida√ß√£o e ordena√ß√£o...")
        salvar_xml_consolidado(resultados_globais)
    else:
        print("\n‚ÑπÔ∏è Nenhuma posi√ß√£o foi encontrada (nenhum match em qualquer tipo)")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üÜï DIAGN√ìSTICO MELHORADO v2.1.6
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def diagnosticar_caso_especifico():
    """üÜï Diagn√≥stico melhorado que detecta todos os problemas poss√≠veis v2.1.6"""
    print("\n" + "=" * 80)
    print("üö® DIAGN√ìSTICO COMPLETO - AN√ÅLISE DE PROBLEMAS DE COORDENADAS")
    print("=" * 80)
    
    arquivo_path = r"C:\Users\arquivo.js"
    texto_copiado = obter_texto_copiado()
    
    if not texto_copiado:
        print("‚ùå Nenhum texto na √°rea de transfer√™ncia!")
        return
    
    if not os.path.exists(arquivo_path):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_path}")
        return
    
    # 1. An√°lise do BOM
    info_encoding = detectar_bom_e_encoding(arquivo_path)
    print(f"üìÑ AN√ÅLISE DO ARQUIVO: uiRenderer.js")
    print(f"üîñ Encoding: {info_encoding['detected']}")
    print(f"üîñ Tem BOM: {info_encoding['has_bom']} ({info_encoding['bom_size']} bytes)")
    
    # 2. An√°lise de quebras de linha
    print(f"\nüìä AN√ÅLISE DE QUEBRAS DE LINHA:")
    
    # Texto copiado
    cr_copiado = texto_copiado.count('\r')
    lf_copiado = texto_copiado.count('\n')
    crlf_copiado = texto_copiado.count('\r\n')
    print(f"üìã Texto copiado:")
    print(f"   \\r (CR): {cr_copiado}")
    print(f"   \\n (LF): {lf_copiado}")
    print(f"   \\r\\n (CRLF): {crlf_copiado}")
    print(f"   Tipo: {'Windows (CRLF)' if crlf_copiado > 0 else 'Unix (LF)' if lf_copiado > 0 else 'Sem quebras'}")
    
    # Arquivo
    conteudo = ler_arquivo_corrigido_bom(arquivo_path)
    cr_arquivo = conteudo.count('\r')
    lf_arquivo = conteudo.count('\n')
    crlf_arquivo = conteudo.count('\r\n')
    print(f"üìÅ Arquivo:")
    print(f"   \\r (CR): {cr_arquivo}")
    print(f"   \\n (LF): {lf_arquivo}")
    print(f"   \\r\\n (CRLF): {crlf_arquivo}")
    print(f"   Tipo: {'Windows (CRLF)' if crlf_arquivo > 0 else 'Unix (LF)' if lf_arquivo > 0 else 'Sem quebras'}")
    
    if (crlf_copiado > 0 and crlf_arquivo == 0) or (crlf_copiado == 0 and crlf_arquivo > 0):
        print(f"üö® PROBLEMA DETECTADO: Quebras de linha incompat√≠veis!")
    
    # 3. Testes de busca
    print(f"\nüîç TESTES DE BUSCA:")
    
    # Busca direta
    pos_direta = conteudo.find(texto_copiado)
    print(f"1. Busca direta: {'‚úÖ ENCONTRADO' if pos_direta != -1 else '‚ùå N√ÉO ENCONTRADO'}")
    if pos_direta != -1:
        print(f"   üìç Posi√ß√£o: {pos_direta}")
    
    # Busca normalizada
    texto_norm = texto_copiado.replace('\r\n', '\n').replace('\r', '\n')
    conteudo_norm = conteudo.replace('\r\n', '\n').replace('\r', '\n')
    pos_norm = conteudo_norm.find(texto_norm)
    print(f"2. Busca normalizada: {'‚úÖ ENCONTRADO' if pos_norm != -1 else '‚ùå N√ÉO ENCONTRADO'}")
    if pos_norm != -1:
        print(f"   üìç Posi√ß√£o normalizada: {pos_norm}")
    
    # Busca primeira linha
    primeira_linha = texto_copiado.split('\n')[0].strip().replace('\r', '')
    pos_primeira = conteudo.find(primeira_linha)
    print(f"3. Busca primeira linha: {'‚úÖ ENCONTRADO' if pos_primeira != -1 else '‚ùå N√ÉO ENCONTRADO'}")
    if pos_primeira != -1:
        print(f"   üìç Posi√ß√£o: {pos_primeira}")
        print(f"   üìù Linha: {repr(primeira_linha[:50])}")
    
    # 4. C√°lculo de coordenadas corretas
    if pos_norm != -1:
        print(f"\nüìê C√ÅLCULO DE COORDENADAS CORRETAS:")
        
        # Mapeia posi√ß√£o normalizada para original
        contador = 0
        pos_real = 0
        for i, char in enumerate(conteudo):
            if contador >= pos_norm:
                pos_real = i
                break
            if char == '\r' and i + 1 < len(conteudo) and conteudo[i + 1] == '\n':
                continue
            contador += 1
        
        # Calcula fim
        fim_real = pos_real + len(texto_copiado)
        
        # Ajusta para BOM se necess√°rio
        pos_final = pos_real + info_encoding['bom_size']
        fim_final = fim_real + info_encoding['bom_size']
        
        print(f"   üìç Posi√ß√£o real (sem BOM): {pos_real} at√© {fim_real}")
        print(f"   üìç Posi√ß√£o final (com BOM): {pos_final} at√© {fim_final}")
        print(f"   üìè Tamanho: {len(texto_copiado)} chars")
        
        # Valida√ß√£o
        texto_extraido = conteudo[pos_real:fim_real]
        texto_extraido_norm = texto_extraido.replace('\r\n', '\n').replace('\r', '\n')
        if texto_extraido_norm == texto_norm:
            print(f"   ‚úÖ VALIDA√á√ÉO: Textos id√™nticos ap√≥s normaliza√ß√£o")
        else:
            print(f"   ‚ö†Ô∏è VALIDA√á√ÉO: Diferen√ßas encontradas")
            print(f"      Extra√≠do: {repr(texto_extraido[:50])}")
            print(f"      Esperado: {repr(texto_copiado[:50])}")
    
    # 5. Compara√ß√£o com XML
    if os.path.exists("sessionlinner.xml"):
        print(f"\nüìã COMPARA√á√ÉO COM XML ATUAL:")
        try:
            tree = ET.parse("sessionlinner.xml")
            root = tree.getroot()
            arquivo1 = root.find('arquivo1')
            if arquivo1:
                inicio_xml = int(arquivo1.find('posicoes/inicio').text)
                fim_xml = int(arquivo1.find('posicoes/fim').text)
                print(f"   üìç Coordenadas no XML: {inicio_xml} at√© {fim_xml}")
                
                if pos_norm != -1:
                    diferenca_inicio = inicio_xml - (pos_real + info_encoding['bom_size'])
                    diferenca_fim = fim_xml - (fim_real + info_encoding['bom_size'])
                    print(f"   üìä Diferen√ßa in√≠cio: {diferenca_inicio:+d} chars")
                    print(f"   üìä Diferen√ßa fim: {diferenca_fim:+d} chars")
                    
                    if diferenca_inicio != 0:
                        print(f"   üö® COORDENADAS INCORRETAS NO XML!")
        except:
            pass
    
    # 6. Teste da fun√ß√£o corrigida
    print(f"\nüîß TESTE DA FUN√á√ÉO calcular_posicoes_precisas v2.1.6:")
    posicoes_corrigidas = calcular_posicoes_precisas(conteudo, texto_copiado, "uiRenderer.js", arquivo_path)
    
    if posicoes_corrigidas:
        print(f"   ‚úÖ FUN√á√ÉO FUNCIONANDO:")
        print(f"      üìç In√≠cio: {posicoes_corrigidas['inicio']}")
        print(f"      üìç Fim: {posicoes_corrigidas['fim']}")
        
        # Valida√ß√£o da fun√ß√£o
        inicio_sem_bom = posicoes_corrigidas['inicio'] - info_encoding['bom_size']
        fim_sem_bom = posicoes_corrigidas['fim'] - info_encoding['bom_size']
        
        if inicio_sem_bom >= 0 and fim_sem_bom <= len(conteudo):
            texto_funcao = conteudo[inicio_sem_bom:fim_sem_bom]
            texto_funcao_norm = texto_funcao.replace('\r\n', '\n').replace('\r', '\n')
            
            if texto_funcao_norm == texto_norm:
                print(f"   ‚úÖ VALIDA√á√ÉO DA FUN√á√ÉO: Perfeita!")
            else:
                print(f"   ‚ö†Ô∏è VALIDA√á√ÉO DA FUN√á√ÉO: Pequenas diferen√ßas")
        else:
            print(f"   ‚ùå VALIDA√á√ÉO DA FUN√á√ÉO: Coordenadas fora dos limites")
    else:
        print(f"   ‚ùå FUN√á√ÉO RETORNOU None")
    
    print(f"\nüéØ RESUMO E RECOMENDA√á√ïES:")
    if crlf_copiado > 0 and crlf_arquivo == 0:
        print(f"   üö® Problema principal: Texto tem CRLF mas arquivo tem apenas LF")
        print(f"   üîß Solu√ß√£o: O script v2.1.6 j√° trata isso automaticamente")
    elif info_encoding['has_bom']:
        print(f"   üö® Problema secund√°rio: Arquivo tem BOM UTF-8")
        print(f"   üîß Solu√ß√£o: Ajustar coordenadas em +{info_encoding['bom_size']} bytes")
    else:
        print(f"   ‚úÖ Arquivo sem BOM, problema apenas nas quebras de linha")
    
    print(f"\n   üí° Execute 'python pythonsearch.py' para recalcular com corre√ß√µes v2.1.6")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß™ FUN√á√ÉO DE TESTE v2.1.6
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def testar_correcoes():
    """üß™ Testa se as corre√ß√µes est√£o funcionando v2.1.6"""
    print("\n" + "=" * 80)
    print("üß™ TESTE DE VALIDA√á√ÉO DAS CORRE√á√ïES v2.1.6")
    print("=" * 80)
    
    # Teste 1: Simula√ß√£o de texto com CRLF em arquivo com LF
    print("üìù TESTE 1: Quebras de linha diferentes")
    conteudo_teste = "linha1\nlinha2\nlinha3\ntexto procurado aqui\nlinha5"
    texto_teste = "texto procurado aqui"
    texto_teste_crlf = "texto procurado aqui"  # Simula CRLF
    
    pos = conteudo_teste.find(texto_teste)
    print(f"   Busca direta: {pos}")
    
    # Teste 2: Mapeamento de posi√ß√µes
    print("\nüìù TESTE 2: Mapeamento com normaliza√ß√£o")
    conteudo_crlf = "linha1\r\nlinha2\r\nlinha3\r\ntexto procurado aqui\r\nlinha5"
    conteudo_norm = conteudo_crlf.replace('\r\n', '\n')
    pos_norm = conteudo_norm.find(texto_teste)
    
    # Mapeia de volta
    contador = 0
    pos_real = 0
    for i, char in enumerate(conteudo_crlf):
        if contador >= pos_norm:
            pos_real = i
            break
        if char == '\r' and i + 1 < len(conteudo_crlf) and conteudo_crlf[i + 1] == '\n':
            continue
        contador += 1
    
    print(f"   Posi√ß√£o normalizada: {pos_norm}")
    print(f"   Posi√ß√£o real mapeada: {pos_real}")
    print(f"   Texto extra√≠do: {repr(conteudo_crlf[pos_real:pos_real+len(texto_teste)])}")
    
    # Teste 3: Com o arquivo real
    arquivo_path = r"C:\Users\arquivo.js"
    if os.path.exists(arquivo_path):
        print("\nüìù TESTE 3: Arquivo real")
        texto_copiado = obter_texto_copiado()
        if texto_copiado:
            # Testa fun√ß√£o calcular_posicoes_precisas
            conteudo = ler_arquivo(arquivo_path)
            posicoes = calcular_posicoes_precisas(conteudo, texto_copiado, "uiRenderer.js", arquivo_path)
            
            if posicoes:
                print(f"   ‚úÖ calcular_posicoes_precisas funcionou!")
                print(f"   üìç Posi√ß√µes: {posicoes['inicio']} at√© {posicoes['fim']}")
                
                # Valida
                inicio_ajustado = posicoes['inicio']
                fim_ajustado = posicoes['fim']
                
                # Remove offset BOM para validar
                info_encoding = detectar_bom_e_encoding(arquivo_path)
                if info_encoding['has_bom']:
                    inicio_ajustado -= info_encoding['bom_size']
                    fim_ajustado -= info_encoding['bom_size']
                
                texto_extraido = conteudo[inicio_ajustado:fim_ajustado]
                texto_extraido_norm = texto_extraido.replace('\r\n', '\n')
                texto_copiado_norm = texto_copiado.replace('\r\n', '\n')
                
                if texto_extraido_norm == texto_copiado_norm:
                    print(f"   ‚úÖ Valida√ß√£o OK: textos id√™nticos ap√≥s normaliza√ß√£o")
                else:
                    print(f"   ‚ùå Valida√ß√£o FALHOU")
                    print(f"      Tamanhos: extra√≠do={len(texto_extraido)}, esperado={len(texto_copiado)}")
            else:
                print(f"   ‚ùå calcular_posicoes_precisas retornou None")
        else:
            print(f"   ‚ö†Ô∏è Nenhum texto na √°rea de transfer√™ncia para testar")
    else:
        print(f"\nüìù TESTE 3: Arquivo uiRenderer.js n√£o encontrado")
    
    print("\n‚úÖ Testes conclu√≠dos!")

def main():
    """Fun√ß√£o principal v2.1.6"""
    print("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print("‚ïë                  PYTHON CTRL+C SEARCH & PASTE TOOL v2.1.6                  ‚ïë")
    print("‚ïë                üö® CORRE√á√ÉO COMPLETA: Quebras de linha diferentes            ‚ïë")
    print("‚ïë                üîß CORRE√á√ÉO: Mapeamento preciso de coordenadas               ‚ïë")
    print("‚ïë                üÜï CORRE√á√ÉO: Ajuste autom√°tico no PASTE                      ‚ïë")
    print("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
    
    if len(sys.argv) > 1:
        comando = sys.argv[1].lower()
        
        if comando == 'paste':
            arquivo_especifico = sys.argv[2] if len(sys.argv) > 2 else None
            posicoes = ler_xml_posicoes(arquivo_especifico)
            
            if posicoes:
                print("üîÑ CRIANDO BACKUP ANTES DA MODIFICA√á√ÉO...")
                backup_sucesso = criar_backup_antes_paste(posicoes['caminho'])
                
                if backup_sucesso:
                    print("‚úÖ Backup criado! Prosseguindo com PASTE...\n")
                    if arquivo_especifico:
                        colar_nas_coordenadas(arquivo_especifico)
                    else:
                        colar_nas_coordenadas()
                else:
                    print("‚ùå ERRO: N√£o foi poss√≠vel criar backup. PASTE cancelado por seguran√ßa!")
            else:
                print("‚ùå ERRO: N√£o foi poss√≠vel obter informa√ß√µes do arquivo. PASTE cancelado!")
        
        elif comando == 'diagnostico':
            diagnosticar_caso_especifico()
        
        elif comando == 'teste':
            testar_correcoes()
        
        else:
            print(f"‚ùå Comando desconhecido: {comando}")
            print("üìã Comandos dispon√≠veis:")
            print("   python pythonsearch.py                    # Busca")
            print("   python pythonsearch.py paste              # Paste no melhor resultado")
            print("   python pythonsearch.py paste arquivo.ext  # Paste em arquivo espec√≠fico")
            print("   python pythonsearch.py diagnostico        # Diagn√≥stico completo")
            print("   python pythonsearch.py teste              # Testa corre√ß√µes")
    else:
        modo_busca()

if __name__ == "__main__":
    main()
